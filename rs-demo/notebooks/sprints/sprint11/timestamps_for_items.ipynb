{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f813fefa-5e26-4471-87f5-79400f02ca3e",
   "metadata": {},
   "source": [
    "## Demo for user story 141"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8fac3b-1399-4ff3-982c-ad7477f455d5",
   "metadata": {},
   "source": [
    "The following scenario demonstrates the implementation of User Story 141 for the RS Server Catalog.\n",
    "\n",
    "The story 141 implements the timestamps for items:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b83b7f-4bc4-4b7d-9a62-116030cb3364",
   "metadata": {},
   "source": [
    "- \"published\" field, set up when the item is inserted.\n",
    "- \"expires\" field, set up when the item is inserted. The expiration range (in days) is stored in a environment variable. If not, the default value is 30 days.\n",
    "- \"updated\" field, set up when the item is inserted or updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863e8be-f33f-4638-a8b6-b7b81a31bb7c",
   "metadata": {},
   "source": [
    "These 3 fields are automatically added in the item properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8842d-e5e5-4f87-88ee-d0b5d08342ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import getpass\n",
    "import pprint \n",
    "\n",
    "APIKEY_HEADER = \"x-api-key\"\n",
    "COLLECTION_NAME = \"S1_L1\"\n",
    "TIMEOUT = 10\n",
    "\n",
    "# In local mode, all the rs-server services are running locally.\n",
    "# For cluster mode, the rs-server services are deployed on the cluster.\n",
    "local_mode = (os.getenv(\"RSPY_LOCAL_MODE\") == \"1\")\n",
    "\n",
    "# In local mode, the catalog service URL is hardcoded in the docker-compose file\n",
    "if local_mode:\n",
    "    rs_server_href=\"\"\n",
    "    RSPY_HOST_CATALOG = \"http://rs-server-catalog:8000\"\n",
    "    RSPY_HOST_AUXIP = \"http://rs-server-adgs:8000\"    \n",
    "    user = \"user\"    \n",
    "# In cluster mode, the catalog service URL is set in an environment variables\n",
    "else:\n",
    "    RSPY_HOST_CATALOG = os.environ[\"RSPY_WEBSITE\"]    \n",
    "    rs_server_href = os.environ[\"RSPY_WEBSITE\"]\n",
    "    user = \"ycolera\"\n",
    "\n",
    "apikey = os.getenv(\"RSPY_APIKEY\")\n",
    "\n",
    "print(f\"Catalog service: {RSPY_HOST_CATALOG}\") \n",
    "print(f\"User: {user}\")\n",
    "\n",
    "if (not local_mode) and (not apikey):    \n",
    "    apikey = getpass.getpass(\"Enter your API key:\")\n",
    "    os.environ[\"RSPY_APIKEY\"] = apikey\n",
    "\n",
    "# Used later in the requests for endpoints\n",
    "apikey_headers: dict = (\n",
    "            {\"headers\": {APIKEY_HEADER: apikey}} if apikey else {}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99700ae2-6bd9-49f6-aa71-cb1ebd26b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning from any previous runs\n",
    "requests.delete(f\"{RSPY_HOST_CATALOG}/catalog/collections/{COLLECTION_NAME}\",\n",
    "                           **apikey_headers,\n",
    "                        timeout = TIMEOUT,)\n",
    "\n",
    "# Checking if the COLLECTION_NAME is present within the catalog. The response should be `Not Found`` (404)\n",
    "response = requests.get(f\"{RSPY_HOST_CATALOG}/catalog/collections/{COLLECTION_NAME}\",\n",
    "                        **apikey_headers,\n",
    "                        timeout = TIMEOUT,)\n",
    "assert response.status_code == 404\n",
    "print(f\"The collection {COLLECTION_NAME} does not exist\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2da078-f978-47fa-a77e-ad809e4ea6ac",
   "metadata": {},
   "source": [
    "## Create a collection to serve as the base for the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2badf539-4acf-4ada-a3dd-63c570280d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = {\n",
    "            \"id\": COLLECTION_NAME,\n",
    "            \"type\": \"Collection\",\n",
    "            \"description\": \"S1_L1 default description\",\n",
    "            \"stac_version\": \"1.0.0\",            \n",
    "            \"owner\": user,\n",
    "        }\n",
    "print(\"Sending the request to create a collection\")\n",
    "post_response = requests.post(f\"{RSPY_HOST_CATALOG}/catalog/collections\", \n",
    "                              json=collection,\n",
    "                              **apikey_headers,\n",
    "                              timeout = TIMEOUT,)\n",
    "post_response.raise_for_status()\n",
    "\n",
    "print(\"Get the collection that was just created by using the ownerId parameter\")\n",
    "response = requests.get(f\"{RSPY_HOST_CATALOG}/catalog/collections/{user}:{COLLECTION_NAME}\",\n",
    "                        **apikey_headers,\n",
    "                        timeout = TIMEOUT,)\n",
    "response.raise_for_status()\n",
    "\n",
    "username_used = json.loads(response.content)\n",
    "\n",
    "print(\"Get the collection that was just created without using the ownerId parameter\")\n",
    "response = requests.get(f\"{RSPY_HOST_CATALOG}/catalog/collections/{COLLECTION_NAME}\",\n",
    "                        **apikey_headers,\n",
    "                        timeout = TIMEOUT,)\n",
    "response.raise_for_status()\n",
    "username_unused = json.loads(response.content)\n",
    "\n",
    "assert username_used == username_unused\n",
    "pprint.PrettyPrinter(indent=4).pprint(username_unused)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5379f103-57cd-422a-a8b1-4bdd22fee4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two buckets have to be created in local mode. \n",
    "# They are used for staging 2 files from the ADGS station\n",
    "# If in cluster mode, they are already created\n",
    "RSPY_TEMP_BUCKET = \"rs-cluster-temp\"\n",
    "RSPY_CATALOG_BUCKET = \"rs-cluster-catalog\"\n",
    "if local_mode:\n",
    "    !pip install boto3\n",
    "    !pip install botocore\n",
    "    import boto3, botocore\n",
    "    print(f\"Creating buckets {RSPY_TEMP_BUCKET} and {RSPY_CATALOG_BUCKET}\")\n",
    "    s3_session = boto3.session.Session()\n",
    "    s3_client = s3_session.client(\n",
    "        service_name=\"s3\",\n",
    "        aws_access_key_id=os.environ[\"S3_ACCESSKEY\"],\n",
    "        aws_secret_access_key=os.environ[\"S3_SECRETKEY\"],\n",
    "        endpoint_url=os.environ[\"S3_ENDPOINT\"],\n",
    "        region_name=os.environ[\"S3_REGION\"],\n",
    "    )\n",
    "    BUCKETS = [RSPY_TEMP_BUCKET, RSPY_CATALOG_BUCKET]  # bucket names under S3_ENDPOINT\n",
    "    BUCKET_DIR = \"stations\"\n",
    "    BUCKET_URL = f\"s3://{BUCKETS[0]}/{BUCKET_DIR}\" \n",
    "    for b in BUCKETS:\n",
    "        try:\n",
    "            s3_client.create_bucket(Bucket=b)\n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            print(f\"Bucket {b} error: {e}\")\n",
    "else:\n",
    "    print(\"The demo is running in the cluster mode, so no need to create the buckets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1df6638-0f25-40f7-aceb-4fe7b7798011",
   "metadata": {},
   "source": [
    "## Staging 2 files from ADGS station by using the RsClient libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733d90a-9a8e-4cd5-af68-ab00eaf16c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rs_common\n",
    "# Set logger level to info\n",
    "import logging\n",
    "rs_common.logging.Logging.level = logging.INFO\n",
    "from rs_client.rs_client import RsClient\n",
    "from datetime import datetime\n",
    "from rs_common.config import EDownloadStatus\n",
    "from time import sleep\n",
    "\n",
    "# Init a generic RS-Client instance. Pass the:\n",
    "#   - RS-Server website URL\n",
    "#   - API key. If not set, we try to read it from the RSPY_APIKEY environment variable.\n",
    "#   - ID of the owner of the STAC catalog collections.\n",
    "#     By default, this is the user login from the keycloak account, associated to the API key.\n",
    "#     Or, in local mode, this is the local system username.\n",
    "#     Else, your API Key must give you the rights to read/write on this catalog owner (see next cell).\n",
    "#   - Logger (optional, a default one can be used)\n",
    "generic_client = RsClient(rs_server_href, rs_server_api_key=None, owner_id=user, logger=None)\n",
    "# From this generic instance, get a Stac client instance\n",
    "stac_client = generic_client.get_stac_client()\n",
    "\n",
    "# From this generic instance, get an Auxip client instance\n",
    "auxip_client = generic_client.get_auxip_client()\n",
    "\n",
    "# Let's stage 2 files on the s3 bucket to prepare them for insertion into the collection\n",
    "temp_s3_files = []\n",
    "\n",
    "# Define a search interval\n",
    "start_date = datetime(2010, 1, 1, 12, 0, 0)\n",
    "stop_date = datetime(2024, 1, 1, 12, 0, 0)\n",
    "\n",
    "files = auxip_client.search_stations(start_date, stop_date, limit=2)\n",
    "assert len(files) == 2\n",
    "\n",
    "for found_file in files:\n",
    "    # We stage by filename = the file ID\n",
    "    first_filename = found_file[\"id\"]\n",
    "\n",
    "    # We must give a temporary S3 bucket path where to copy the file from the station.\n",
    "    # Use our API key username so avoid conflicts with other users.\n",
    "    # NOTE: in future versions, this S3 path will be automatically calculated by RS-Server.\n",
    "    s3_path = f\"s3://{RSPY_TEMP_BUCKET}/{user}/ADGS\"\n",
    "    temp_s3_files.append (f\"{s3_path}/{first_filename}\") # save it for later\n",
    "\n",
    "    # We can also download the file locally to the server, but this is useful only in local mode\n",
    "    local_path = None\n",
    "\n",
    "    # Call the staging service\n",
    "    auxip_client.staging(first_filename, s3_path=s3_path, tmp_download_path=local_path)\n",
    "\n",
    "    # Then we can check when the staging has finished by calling the check status service\n",
    "    while True:\n",
    "        status = auxip_client.staging_status(first_filename)\n",
    "        print (f\"Staging status for {first_filename!r}: {status.value}\")\n",
    "        if status in [EDownloadStatus.DONE, EDownloadStatus.FAILED]:\n",
    "            print(\"\\n\")\n",
    "            break\n",
    "        sleep(1)        \n",
    "    assert status == EDownloadStatus.DONE, \"Staging has failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af54f0-15e8-4b76-9905-e80cbb0624f9",
   "metadata": {},
   "source": [
    "## We will create 2 stac items by using the files we staged from the ADGS station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b96af-94e0-4b2b-bf39-14d3d78a40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac.asset import Asset\n",
    "from pystac.item import Item\n",
    "geometry = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [[[-180, -90], [180, -90], [180, 90], [-180, 90], [-180, -90]]],\n",
    "}\n",
    "bbox = [-180.0, -90.0, 180.0, 90.0]\n",
    "# Simulated values\n",
    "WIDTH=2500\n",
    "HEIGHT=2500\n",
    "\n",
    "items = []\n",
    "ids = []\n",
    "for temp_s3_file in temp_s3_files:\n",
    "\n",
    "    # Let's use STAC item ID = filename\n",
    "    print(f\"Create a stac item from file: {temp_s3_file!r}\")\n",
    "    item_id = os.path.basename(temp_s3_file)\n",
    "    ids.append(item_id)\n",
    "\n",
    "    # The file path from the temp s3 bucket is given in the assets\n",
    "    assets = {\"file\": Asset(href=temp_s3_file)}\n",
    "    \n",
    "    now = datetime.now()\n",
    "    properties = {\n",
    "        \"gsd\": 0.12345,\n",
    "        \"width\": WIDTH,\n",
    "        \"height\": HEIGHT,\n",
    "        \"datetime\": datetime.now(),\n",
    "        \"proj:epsg\": 3857,\n",
    "        \"orientation\": \"nadir\",\n",
    "    }\n",
    "\n",
    "    # Add item to the STAC catalog collection, check status is OK\n",
    "    # NOTE: in future versions, this pystac Item object will be returned automatically by rs-client-libraries.\n",
    "    items.append(Item(\n",
    "        collection=COLLECTION_NAME,\n",
    "        id=item_id,\n",
    "        geometry=geometry,\n",
    "        bbox=bbox,\n",
    "        datetime=now,\n",
    "        properties=properties,\n",
    "        assets=assets))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099312f5-67f2-49a0-9480-66de45154229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first item inside the collection by using the username inside the endpoint\n",
    "response = requests.post(\n",
    "    f\"{RSPY_HOST_CATALOG}/catalog/collections/{user}:{COLLECTION_NAME}/items\",\n",
    "    json=items[0].to_dict(),\n",
    "    **apikey_headers,\n",
    "    timeout = TIMEOUT,\n",
    ")\n",
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415dc003-3b11-4835-8c63-325b2b8c5992",
   "metadata": {},
   "source": [
    "## We will post a new item and check that the 3 fields are correctly added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc1b62-f12a-48b7-bb2e-7753e4d0669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = \"S2__OPER_AUX_ECMWFD_PDMC_20200216T120000_V20190217T090000_20190217T210000.TGZ\"\n",
    "item_response = requests.get(f\"{RSPY_HOST_CATALOG}/catalog/collections/{user}:{COLLECTION_NAME}/items/{item_id}\", **apikey_headers, timeout=TIMEOUT)\n",
    "item_response.raise_for_status()\n",
    "\n",
    "content = json.loads(item_response.content)\n",
    "\n",
    "assert \"expires\" in content[\"properties\"]\n",
    "assert \"updated\" in content[\"properties\"]\n",
    "assert \"published\" in content[\"properties\"]\n",
    "\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42f15b-8b92-45b8-a2df-e248f48a69ec",
   "metadata": {},
   "source": [
    "## We will modify this item and call a PUT method and check that the updated field is correctly updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8285fe-20de-4025-9a45-4659962e0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "modified_content = copy.deepcopy(content)\n",
    "del modified_content[\"collection\"]\n",
    "\n",
    "modified_content[\"properties\"] =  {'gsd': 0.12345,\n",
    "  'owner': 'ycolera',\n",
    "  'width': 3000,\n",
    "  'height': 2500,\n",
    "  'datetime': '2024-06-26T15:07:56.699718Z',\n",
    "  'proj:epsg': 3857,\n",
    "  'orientation': 'nadir'}\n",
    "\n",
    "modified_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35065dba-156b-4257-b621-89e41b8b8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "put_response = requests.put(f\"{RSPY_HOST_CATALOG}/catalog/collections/{user}:{COLLECTION_NAME}/items/{item_id}\", json=modified_content, **apikey_headers, timeout=TIMEOUT)\n",
    "put_response.raise_for_status()\n",
    "\n",
    "new_item = requests.get(f\"{RSPY_HOST_CATALOG}/catalog/collections/{user}:{COLLECTION_NAME}/items/{item_id}\", **apikey_headers, timeout=TIMEOUT)\n",
    "new_item_content = json.loads(new_item.content)\n",
    "\n",
    "assert new_item_content[\"properties\"][\"updated\"] != content[\"properties\"][\"updated\"]\n",
    "\n",
    "new_item_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f75dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_response = requests.delete(f\"{RSPY_HOST_CATALOG}/catalog/collections/{user}:{COLLECTION_NAME}\")\n",
    "deleted_response.raise_for_status()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
